---
layout: post
title: Code Close to Completion
subtitle: Progress Report 7
cover-img: /assets/img/whitemushroom.jpeg
thumbnail-img: /assets/img/whitemushroom.jpeg
share-img: /assets/img/whitemushroom.jpeg
#gh-repo: sonikarichamodur/sonikarichamodur.github.io
#gh-badge: [star, follow]
tags: [code]
comments: true
---
The code for my research project has been completed up until classification of mushroom instances and overfitting mitigation. 

Here are the key components and outputs of my code:

Encoding categorical data:

![alt-text-1](/assets/img/EncodeData1.png "title") 
![alt-text-1](/assets/img/EncodeData2.png "title") 
![alt-text-1](/assets/img/EncodeData3.png "title") 

Feature Selection:

![alt-text-1](/assets/img/FeatureSelection1.png "title") 
![alt-text-1](/assets/img/FeatureSelection2.png "title") 

Define Evaluation Metrics:
![alt-text-1](/assets/img/Overfitting1.png "title") 
- Accuracy: percentage of correct predictions
- Precision: Rate of correctly predicting toxic mushrooms
- Recall: Rate of correctly predicting edible mushrooms 

Overfitting Mitigation:
K fold cross validation was used, with the stratified variant in particular. Due to this implementation, it will take longer to run the model, but since this dataset is not very large, it should be fine.
![alt-text-1](/assets/img/Overfitting2.png "title") 

Why stratified?
It will retain the percentage of samples for each class when implemented to make the splits. It would not be good to have one group with too many red mushrooms, for example.

Logistic Regression classifier:
![alt-text-1](/assets/img/LogisticRegression1.png "title") 

Naive Bayes classifier:
![alt-text-1](/assets/img/NaiveBayes1.png "title")

Support Vector Machine Classifier:
![alt-text-1](/assets/img/SVM1.png "title")

I still have to write code for the clustering analysis on my dataset. 