---
layout: page
---
![alt-text-1](/assets/img/Coursework.png "title")

## <font color="#E34000"><b>Mathematics in Machine Learning (by Coursera)</b></font>
<p>
I took this course to acquire an understanding of the mathematical calculations and transformations that occur behind the scenes of the code for a machine learning algorithm. The course had three parts where I learned the following:
</p>
<p><b>Linear Algebra:</b></p>
<ul>
   <li>Fundamentals of <b>vectors</b>: changing basis and linear independence.</li>
   <li><b>Matrix</b> transformations: inversion and rotation, to name a few.</li>
   <li>Einstein Summation Convention</li>
   <li><b>Gram Schmidt Process</b> with coding assignment</li>
   <li><b>Eigenvectors</b> and <b>PageRank</b> algorithm with coding assignment</li>
</ul> 

<p><b>Multivariate Calculus:</b></p>   
<ul>
   <li><b>Derivatives</b>: Jacobian, Hessian, Maclaurin Series, Taylor Series</li>
   <li>How <b>back propagation</b> relates to neural networks with coding assignment</li>
   <li>Newton-Raphson Method</li>
   <li><b>Gradient Descent</b> with coding assignment</li>
   <li>Mathematics behind <b>Simple Linear Regression</b></li>
</ul>

<b>Principal Component Analysis (PCA):</b>
<ul>
   <li><b>Statistics</b> of datasets</li>
   <li>Inner products</li>
   <li>Orthogonal <b>projections</b></li>
   <li><b>PCA:</b> the most commonly used method to reduce the dimensions of a dataset.</li>
</ul>

## <font color="#E34000"><b>Machine Learning A-Z (by Udemy)</b></font>

I took this course to learn about the use cases and implementations of many different types of machine learning algorithms. The course covered several data preprocessing steps, along with many regression, classification, clustering, and association rule learning algorithms. I also learned about more advanced forms of machine learning, such as reinforcement learning, natural language processing, and deep learning. The course then went over dimensionality reduction algorithms such as PCA, techniques to select a model, and lastly, a brief look into ensemble learning through XGBoost. 


I will be implementing many of the data preprocessing techniques I learned, since my dataset has categorical variables and missing values. I learned how to implement the algorithms I chose for my project--Random Forest, Logistic Regression, and K-Nearest Neighbors--and developed a more profound understanding of binary classifiers. The course opened my eyes to how clustering would be insightful for my dataset and how it would add an another facet of originality to my project. I also learned performance evaluation techniques that I will be using as my dependent variables, which are confusion matrices and the Cumulative Accuracy Profile. 

For a deep dive into everything that I learned from this course, take a look at this <a href="https://docs.google.com/presentation/d/1L71zkIscJ5ZZDIwhzWjfsHgV5wIZiNGNr852hXJgFSA/edit?usp=sharing">presentation.</a>
